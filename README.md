# Mem - Temporal Video Intelligence System

**Capture everything. Store efficiently. Process intelligently.**

Mem is a production-ready video processing system that captures frames and transcriptions from video files and live streams, storing them with absolute UTC timestamps. Built for continuous recording scenarios (security cameras, screen recording, life logging), Mem achieves **95% storage reduction** through intelligent frame deduplication while maintaining instant temporal access to any moment.

## ğŸ¯ Why Mem?

Traditional video storage is expensive and inefficient. A 24/7 security camera generates ~2.4GB per day, but 95% of frames are redundant. Mem solves this by:

- **Deduplicating identical frames** using perceptual hashing (120MB vs 2.4GB per day)
- **Anchoring everything to UTC time** for precise temporal queries
- **Separating capture from analysis** - store once, process many times
- **Supporting both files and live streams** from OBS Studio or IP cameras
- **GPU-accelerated transcription** with local Whisper models (no cloud dependencies)

## âœ¨ Key Features

- ğŸ“Š **95% Storage Reduction** - Perceptual hash deduplication for static scenes
- â° **Temporal Architecture** - All data anchored to absolute UTC timestamps
- ğŸ”´ **Live Streaming** - RTMP server for OBS Studio and IP cameras
- ğŸ¯ **GPU Acceleration** - CUDA-enabled Whisper transcription
- ğŸ—„ï¸ **Self-Contained** - Frames stored as BLOBs in DuckDB, no filesystem dependencies
- ğŸ”’ **Privacy-First** - All processing happens locally, no cloud APIs
- ğŸš€ **Production-Ready** - Docker deployment with health checks and monitoring

## ğŸš€ Quick Start

### Option 1: Local Development

```bash
# Clone repository
git clone <repository-url>
cd mem

# Start full stack (backend + frontend)
./start-mem.sh

# Access the application
# Frontend: http://localhost:3000
# Backend API: http://localhost:8000
# API Docs: http://localhost:8000/docs
```

### Option 2: Docker Deployment

```bash
# Start all services with Docker Compose
docker-compose up -d

# Services will be available at:
# Frontend: http://localhost
# Backend API: http://localhost:8000
# RTMP Stream: rtmp://localhost:1935/live
```

### Option 3: Manual Setup

```bash
# Backend
cd mem
uv sync
uv run uvicorn src.api.app:app --reload --port 8000

# Frontend (new terminal)
cd mem-ui
npm install
npm run dev

# Access at http://localhost:5173
```

## ğŸ“¹ Processing Videos

### Important: Filename Format
Videos **MUST** be named `YYYY-MM-DD_HH-MM-SS.mp4` (UTC timestamp when recording started)

```bash
# Process a video via API
curl -X POST http://localhost:8000/api/capture \
  -H "Content-Type: application/json" \
  -d '{"filepath": "/path/to/2025-08-22_14-30-45.mp4"}'

# Or use the web UI
# 1. Navigate to http://localhost:3000
# 2. Click the Upload button
# 3. Select your video file
```

## ğŸ”´ Live Streaming with OBS

### 1. Create Stream Session (Web UI)
- Open http://localhost:3000
- Click "Streams" button in header
- Click "Create New Stream"
- Copy the stream key

### 2. Configure OBS Studio
- Settings â†’ Stream
- Service: **Custom**
- Server: `rtmp://localhost:1935/live`
- Stream Key: *(paste from UI)*

### 3. Start Streaming
- Click Play button on stream card in UI
- Start streaming in OBS
- Watch real-time stats and deduplication

## ğŸ“Š Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Input Sources                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚Video Files â”‚        â”‚ RTMP Streams (OBS/IP)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                           â”‚
         â–¼                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Capture Pipeline                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Frame Extractâ”‚â”€â”€â”€â–¶â”‚ Perceptual Hashing (95%  â”‚   â”‚
â”‚  â”‚  (5 sec)    â”‚    â”‚ deduplication)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚Audio Extractâ”‚â”€â”€â”€â–¶â”‚ Whisper Transcription    â”‚   â”‚
â”‚  â”‚             â”‚    â”‚ (GPU Accelerated)        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              DuckDB Storage Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Tables:                                      â”‚   â”‚
â”‚  â”‚ â€¢ unique_frames (BLOB storage)              â”‚   â”‚
â”‚  â”‚ â€¢ timeline (temporal index)                 â”‚   â”‚
â”‚  â”‚ â€¢ transcriptions (Whisper output)           â”‚   â”‚
â”‚  â”‚ â€¢ sources (videos/streams metadata)         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Access Layer                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ REST API â”‚   â”‚  Web UI  â”‚   â”‚ Future: AI    â”‚   â”‚
â”‚  â”‚  (8000)  â”‚   â”‚  (3000)  â”‚   â”‚  Processing   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Development

### Prerequisites
- Python 3.9 (exact version required)
- Node.js 18+ and npm
- FFmpeg for audio/video processing
- CUDA toolkit (optional, for GPU acceleration)

### Development Commands

```bash
# Backend
cd mem
uv sync                     # Install dependencies
make format                 # Auto-format code
make lint                   # Run linters
uv run pytest tests/        # Run tests

# Frontend
cd mem-ui
npm install                 # Install dependencies
npm run dev                 # Start dev server
npm run test               # Run tests
npm run build              # Build for production

# Full Stack
./start-mem.sh             # Start everything
./stop-mem.sh              # Stop everything
```

### Using Nix (Recommended)
```bash
# Enter development environment with all dependencies
nix develop

# Run commands with guaranteed dependencies
nix develop -c uv run uvicorn src.api.app:app --reload
```

## ğŸ“ˆ Performance Metrics

| Metric | Value | Notes |
|--------|-------|-------|
| Storage Reduction | 95% | Via perceptual hashing |
| Daily Storage | ~120MB | For 24/7 recording |
| Query Latency | <100ms | Time-range searches |
| Frame Processing | 30 fps | On modern hardware |
| Stream Latency | <1 second | RTMP to database |
| Max Concurrent Streams | 10 | Configurable |

## ğŸ”§ Configuration

### Backend (`mem/config.yaml`)
```yaml
capture:
  frame_interval_seconds: 5    # Extract frame every N seconds
  jpeg_quality: 85             # JPEG compression (1-100)

whisper:
  model: "base"                # tiny/base/small/medium/large
  device: "cuda"               # cuda or cpu
  compute_type: "float16"      # float16 (GPU) or int8 (CPU)

streaming:
  rtmp:
    port: 1935
    max_concurrent_streams: 10
```

## ğŸ³ Docker Deployment

### Production Deployment with GPU

```bash
# Build and push images
./deploy/build-and-push.sh

# Deploy to server
./deploy/deploy-to-wise18.sh

# Or manually with docker-compose
docker-compose -f docker-compose.yml up -d
```

### GPU Requirements
- NVIDIA GPU with CUDA support
- nvidia-docker runtime installed
- 4GB+ VRAM for optimal performance

## ğŸ“š API Documentation

Interactive API documentation available at http://localhost:8000/docs

### Core Endpoints

```bash
# Process video
POST /api/capture
{"filepath": "/path/to/video.mp4"}

# Search timeline
GET /api/search?type=timeline&start=2025-01-01&end=2025-01-02

# Get system status
GET /api/status

# Stream management
POST /api/streams/create
GET /api/streams
POST /api/streams/{stream_key}/start
```

## ğŸ§ª Testing

```bash
# Run all tests
cd mem && uv run pytest tests/

# Run with coverage
uv run pytest tests/ --cov=src --cov-report=html

# Frontend tests
cd mem-ui && npm run test
```

## ğŸ“¦ Project Structure

```
mem/
â”œâ”€â”€ mem/                    # Backend (Python/FastAPI)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ api/           # REST API endpoints
â”‚   â”‚   â”œâ”€â”€ capture/       # Frame/audio extraction
â”‚   â”‚   â””â”€â”€ storage/       # DuckDB operations
â”‚   â””â”€â”€ tests/             # Unit tests
â”œâ”€â”€ mem-ui/                 # Frontend (React/TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/    # React components
â”‚   â”‚   â”œâ”€â”€ hooks/         # Custom hooks
â”‚   â”‚   â””â”€â”€ utils/         # API client
â”‚   â””â”€â”€ tests/             # Frontend tests
â”œâ”€â”€ rtmp/                   # RTMP streaming server
â”œâ”€â”€ deploy/                 # Deployment scripts
â””â”€â”€ docker-compose.yml      # Container orchestration
```

## ğŸš§ Current Limitations

- Videos must follow `YYYY-MM-DD_HH-MM-SS.mp4` naming convention
- No built-in authentication (use reverse proxy)
- Synchronous video processing (async coming soon)
- Maximum 10 concurrent streams (configurable)

## ğŸ—ºï¸ Roadmap

- [ ] Authentication and multi-user support
- [ ] Async video processing with job queue
- [ ] Cloud storage backends (S3, GCS)
- [ ] AI-powered scene analysis
- [ ] Mobile app for viewing
- [ ] Export to standard formats
- [ ] Kubernetes deployment

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Ensure tests pass (`make test`)
5. Format code (`make format`)
6. Submit a pull request

## ğŸ“„ License

MIT License - See [LICENSE](LICENSE) file for details

## ğŸ™ Acknowledgments

- [OpenAI Whisper](https://github.com/openai/whisper) for transcription
- [DuckDB](https://duckdb.org/) for time-series storage
- [FastAPI](https://fastapi.tiangolo.com/) for the backend framework
- [React](https://reactjs.org/) for the frontend framework

---

**Built with â¤ï¸ for continuous recording and temporal intelligence**